{"cells":[{"cell_type":"markdown","source":["# 08_tensorflow_transfer_callback"],"metadata":{"id":"44QtaY5CS6CJ"},"id":"44QtaY5CS6CJ"},{"cell_type":"markdown","id":"02449263","metadata":{"id":"02449263"},"source":["## 함수형 API (Functional API) -"]},{"cell_type":"markdown","id":"a395a585","metadata":{"id":"a395a585"},"source":[]},{"cell_type":"markdown","id":"967be7de","metadata":{"id":"967be7de"},"source":["Sequential API - 입력부터 출력까지 일직선으로 연결, 직관적으로 편리함."]},{"cell_type":"markdown","id":"63161cbb","metadata":{"id":"63161cbb"},"source":["Functional API - 여러개의 층 공유, 다양한 종류의 입출력 등 일직선 구조 한계를 보완해줌."]},{"cell_type":"markdown","id":"ec0985d5","metadata":{"id":"ec0985d5"},"source":["## example 1)"]},{"cell_type":"markdown","source":[],"metadata":{"id":"rPYEo9PDTJIb"},"id":"rPYEo9PDTJIb"},{"cell_type":"code","execution_count":null,"id":"8f76f79b","metadata":{"id":"8f76f79b","outputId":"0acca08a-ddb3-4c16-c18c-b21e93fab573"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 4)]               0         \n","                                                                 \n"," dense (Dense)               (None, 8)                 40        \n","                                                                 \n"," dense_1 (Dense)             (None, 16)                144       \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                544       \n","                                                                 \n"," dense_3 (Dense)             (None, 10)                330       \n","                                                                 \n","=================================================================\n","Total params: 1,058\n","Trainable params: 1,058\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["#Sequential API 를 Functional API 로 구현\n","\n","import tensorflow as tf\n","\n","from tensorflow.keras.layers import Input, Dense\n","from tensorflow.keras.models import Model\n","\n","input_ = Input(shape = (4,))\n","\n","x = Dense(8, activation = 'relu')(input_)\n","x = Dense(16, activation = 'relu')(x)\n","x = Dense(32, activation = 'relu')(x)\n","\n","output_ = Dense(10, activation = 'softmax')(x)\n","\n","md = Model(inputs = input_, outputs = output_)\n","md.summary()"]},{"cell_type":"markdown","source":["## example 2)"],"metadata":{"id":"_FU-S3NHTFcf"},"id":"_FU-S3NHTFcf"},{"cell_type":"markdown","source":[],"metadata":{"id":"9SDE41V3TKHm"},"id":"9SDE41V3TKHm"},{"cell_type":"code","execution_count":null,"id":"8fe346f8","metadata":{"scrolled":false,"id":"8fe346f8","outputId":"786c8a40-1121-4457-8ecc-5707ab9e231b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_5\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_4 (InputLayer)           [(None, 4)]          0           []                               \n","                                                                                                  \n"," dense_7 (Dense)                (None, 8)            40          ['input_4[0][0]']                \n","                                                                                                  \n"," input_5 (InputLayer)           [(None, 8)]          0           []                               \n","                                                                                                  \n"," dense_8 (Dense)                (None, 16)           144         ['dense_7[0][0]']                \n","                                                                                                  \n"," dense_9 (Dense)                (None, 8)            72          ['input_5[0][0]']                \n","                                                                                                  \n"," concatenate_1 (Concatenate)    (None, 24)           0           ['dense_8[0][0]',                \n","                                                                  'dense_9[0][0]']                \n","                                                                                                  \n"," dense_10 (Dense)               (None, 10)           250         ['concatenate_1[0][0]']          \n","                                                                                                  \n","==================================================================================================\n","Total params: 506\n","Trainable params: 506\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["# 다중 입력 in Functional API\n","\n","from tensorflow.keras.layers import concatenate\n","\n","#입력층 1에 대한 신경망\n","input1 = Input(shape = (4,))\n","\n","hidden1 = Dense(8, activation = 'relu')(input1)\n","hidden2 = Dense(16, activation = 'relu')(hidden1)\n","\n","output1 = Model(inputs = input1, outputs = hidden2)\n","\n","#입력층 2에 대한 신경망\n","input2 = Input(shape = (8,))\n","\n","hidden3 = Dense(8, activation = 'relu')(input2)\n","\n","output2 = Model(inputs = input2, outputs = hidden3)\n","\n","#층 연결\n","result = concatenate([output1.output, output2.output])\n","\n","#출력층 정의\n","output = Dense(10, activation = 'softmax')(result)\n","\n","#최종 모델 구축\n","md = Model(inputs = [output1.input, output2.input], outputs = output)\n","md.summary()"]},{"cell_type":"markdown","id":"f79b63d4","metadata":{"id":"f79b63d4"},"source":[]},{"cell_type":"markdown","id":"716e6aa0","metadata":{"id":"716e6aa0"},"source":["## MNIST CNN modeling exmple in Functional API)"]},{"cell_type":"markdown","id":"0504510c","metadata":{"id":"0504510c"},"source":[]},{"cell_type":"code","execution_count":null,"id":"112aafa8","metadata":{"id":"112aafa8"},"outputs":[],"source":["from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.layers import Input, Conv2D, MaxPool2D\n","from tensorflow.keras.layers import Dense, Flatten, Dropout\n","\n","(xtr, ytr), (xt, yt) = mnist.load_data()\n","\n","xtr = xtr.reshape(-1, 28,28, 1)\n","xt = xt.reshape(-1, 28, 28, 1)\n","\n","xtr = xtr / 255.0\n","xt = xt / 255.0"]},{"cell_type":"code","execution_count":null,"id":"c0b32809","metadata":{"id":"c0b32809"},"outputs":[],"source":["input_ = Input(shape = (28, 28, 1))\n","\n","x = Conv2D(32, 3, activation = 'relu')(input_)\n","x = Conv2D(64, 3, activation = 'relu')(x)\n","x = MaxPool2D(pool_size = (2, 2))(x)\n","x = Dropout(0.25)(x)\n","\n","x = Flatten()(x)\n","\n","x = Dense(128, activation = 'relu')(x)\n","x = Dropout(0.5)(x)\n","\n","output_ = Dense(10, activation = 'softmax')(x)\n","cnn = Model(inputs = input_, outputs = output_)"]},{"cell_type":"code","execution_count":null,"id":"e4d372fa","metadata":{"id":"e4d372fa"},"outputs":[],"source":["#CNN 모델 컴파일 및 학습\n","\n","cnn.compile(loss = 'sparse_categorical_crossentropy', optimizer = tf.keras.optimizers.Adam(),\\\n","           metrics = ['accuracy'])\n","\n","hist = cnn.fit(xtr, ytr, batch_size = 128, epochs = 30, validation_data = (xt, yt))"]},{"cell_type":"markdown","id":"5d80e45c","metadata":{"id":"5d80e45c"},"source":[]},{"cell_type":"markdown","id":"f1d72b37","metadata":{"id":"f1d72b37"},"source":["-----------------------------------------------------------------------------------------------"]},{"cell_type":"markdown","id":"7ad662e3","metadata":{"id":"7ad662e3"},"source":["## 전이 학습(Transfer Learning) -"]},{"cell_type":"markdown","id":"179b4dc8","metadata":{"id":"179b4dc8"},"source":["부족한 학습 데이터 문제를 해결하기 위해 등장,"]},{"cell_type":"markdown","id":"85d0d6f0","metadata":{"id":"85d0d6f0"},"source":["ImageNet 데이터를 활용해 학습된 모델의 가중치를 가져와서, 해결하려는 문제에 맞게 보정해서 사용하는 개념,"]},{"cell_type":"markdown","id":"8566da6c","metadata":{"id":"8566da6c"},"source":["사전 학습 모델(pre-trained model) : 큰 데이터셋을 사용해 훈련된 모델."]},{"cell_type":"markdown","id":"dd723437","metadata":{"id":"dd723437"},"source":["사전 학습 모델의 구조 : 사전 학습된 feature extractor / 사전 학습된 classifier"]},{"cell_type":"markdown","id":"a68289c1","metadata":{"id":"a68289c1"},"source":[]},{"cell_type":"markdown","id":"d7c3134d","metadata":{"id":"d7c3134d"},"source":["## 파인 튜닝(fine-tuning)"]},{"cell_type":"markdown","id":"bb80a0a9","metadata":{"id":"bb80a0a9"},"source":["사전 학습 모델의 가중치를 미세하게 조정하는 기법,"]},{"cell_type":"markdown","id":"b98a1fa8","metadata":{"id":"b98a1fa8"},"source":["많은 연산량으로 인해 CPU 보다는 GPU 를 사용."]},{"cell_type":"markdown","id":"a75310e0","metadata":{"id":"a75310e0"},"source":[]},{"cell_type":"markdown","id":"6e55b04d","metadata":{"id":"6e55b04d"},"source":["## transfer learning 활용)"]},{"cell_type":"code","execution_count":null,"id":"1bdac455","metadata":{"id":"1bdac455","outputId":"bdcd38c7-cce1-492c-f079-2af7fb52bccd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"vgg16\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_15 (InputLayer)       [(None, 240, 240, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 240, 240, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 240, 240, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 120, 120, 64)      0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 120, 120, 128)     73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 120, 120, 128)     147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 60, 60, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 60, 60, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 60, 60, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 60, 60, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 30, 30, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 30, 30, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 30, 30, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 30, 30, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 15, 15, 512)       0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 15, 15, 512)       2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 15, 15, 512)       2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 15, 15, 512)       2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n","                                                                 \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 14,714,688\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten, Dropout\n","\n","from tensorflow.keras.applications import VGG16, ResNet50, MobileNet, InceptionV3\n","#tensorflow 에서 제공하는 다양한 사전학습 모델 import\n","\n","base_md = VGG16(weights = 'imagenet', include_top = False, input_shape = (240, 240, 3))\n","#input_shape = (widths, heights, channel)\n","#include_top = False : 특징 추출기만 가져옴, True : 특징 추출기와 분류기 모두 가져옴.\n","base_md.summary()"]},{"cell_type":"markdown","id":"5b838849","metadata":{"id":"5b838849"},"source":["include_top = False 지정하여, conv2D 와 Maxpooling 으로 구성된 특징 추출기만 가져온 것을 알 수 있습니다."]},{"cell_type":"code","execution_count":null,"id":"f5cb3030","metadata":{"id":"f5cb3030","outputId":"59048963-bfdf-4d1c-da30-6c3046e78b02"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n","                                                                 \n"," flatten_5 (Flatten)         (None, 25088)             0         \n","                                                                 \n"," dense_17 (Dense)            (None, 64)                1605696   \n","                                                                 \n"," dropout_9 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_18 (Dense)            (None, 4)                 260       \n","                                                                 \n","=================================================================\n","Total params: 16,320,644\n","Trainable params: 16,320,644\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["md = Sequential()\n","md.add(base_md)\n","#pre_trained model\n","md.add(Flatten())\n","#Flatten - 텐서를 1차원 벡터로 변환시켜줌, 사전 학습된 특징 추출기와 분류기를 연결시켜주는 역할\n","md.add(Dense(64, activation = 'relu'))\n","md.add(Dropout(0.25))\n","md.add(Dense(4, activation = 'softmax'))\n","\n","md.compile(loss = 'sparse_categorical_crossentropy', optimizer = tf.keras.optimizers.Adam(),\\\n","          metrics = ['accuracy'])\n","md.summary()"]},{"cell_type":"markdown","id":"864602f1","metadata":{"id":"864602f1"},"source":["----------------------------------------------------------------------------------------------"]},{"cell_type":"markdown","id":"bcea77b7","metadata":{"id":"bcea77b7"},"source":["## 전이 학습 예제(Cats and Dogs) -"]},{"cell_type":"markdown","id":"eec17010","metadata":{"id":"eec17010"},"source":["Cats and Dogs Dataset : CNN 아키텍쳐 구축 및 평가를 위한 기본 학습 데이터셋"]},{"cell_type":"markdown","id":"03345923","metadata":{"id":"03345923"},"source":["2000 개의 학습 데이터, 1000 개의 테스트 데이터로 구성, 학습 데이터가 부족하기 때문에 전이 학습을 활용!"]},{"cell_type":"code","execution_count":null,"id":"83962028","metadata":{"id":"83962028"},"outputs":[],"source":["#Fine-tuning using pre-trained model(Xception)\n","\n","from tensorflow.keras.applications import Xception\n","#사전 학습 모델 import\n","from tensorflow.keras.layers import GlobalAveragePooling2D\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","#Cats and Dogs 데이터셋 압축풀기\n","import zipfile\n","\n","with zipfile.ZipFile('cats_and_dogs_filtered.zip', 'r') as target_file:\n","\n","    target_file.extractall()"]},{"cell_type":"code","execution_count":null,"id":"41cc1ff0","metadata":{"id":"41cc1ff0","outputId":"fbad4278-1e06-44ab-a270-877a0144651a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," xception (Functional)       (None, 7, 7, 2048)        20861480  \n","                                                                 \n"," global_average_pooling2d (G  (None, 2048)             0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n"," dense_19 (Dense)            (None, 16)                32784     \n","                                                                 \n"," dropout_10 (Dropout)        (None, 16)                0         \n","                                                                 \n"," dense_20 (Dense)            (None, 2)                 34        \n","                                                                 \n","=================================================================\n","Total params: 20,894,298\n","Trainable params: 20,839,770\n","Non-trainable params: 54,528\n","_________________________________________________________________\n"]}],"source":["#모델링(pre-trained Xception + User-Defined Classifier)\n","\n","img_width = 224\n","img_height = 224\n","\n","base_md = Xception(weights = 'imagenet', include_top = False, input_shape = (img_width, img_height, 3))\n","#사전 학습 모델의 feature extractor 만 사용(include_top = False)\n","\n","md = Sequential()\n","\n","md.add(base_md)\n","\n","md.add(GlobalAveragePooling2D())\n","#------------------------------------------- User-Defined Classifier(아래)\n","md.add(Dense(16, activation = 'relu'))\n","md.add(Dropout(0.25))\n","\n","md.add(Dense(2, activation = 'softmax'))\n","#정답은 고양이 또는 개, 총 두개이므로 출력층 노드 : 2\n","md.summary()"]},{"cell_type":"code","execution_count":null,"id":"c0c7f51e","metadata":{"id":"c0c7f51e"},"outputs":[],"source":["#ImageDataGenerator 정의\n","\n","train_dir = './cats_and_dogs_filtered/train'\n","test_dir = './cats_and_dogs_filtered/validation'\n","\n","train_data_gen = ImageDataGenerator(rescale = 1./ 255, \n","                                    rotation_range = 10, width_shift_range = 0.1, \n","                                    height_shift_range = 0.1, shear_range = 0.1, zoom_range = 0.1)\n","\n","test_data_gen = ImageDataGenerator(rescale = 1./255)\n","#이미지 데이터 읽어올 때, 자동으로 정규화"]},{"cell_type":"code","execution_count":null,"id":"5c9ba97b","metadata":{"id":"5c9ba97b","outputId":"c2723ffe-41a7-4a74-a5ce-ed99e0c2903e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 2000 images belonging to 2 classes.\n","Found 1000 images belonging to 2 classes.\n"]}],"source":["train_data = train_data_gen.flow_from_directory(train_dir, batch_size = 32, \n","                                                color_mode = 'rgb', shuffle = True, class_mode = 'categorical',\n","                                                target_size = (img_width,img_height))\n","\n","\n","test_data = test_data_gen.flow_from_directory(test_dir, batch_size = 32, \n","                                              color_mode = 'rgb', shuffle = True, class_mode = 'categorical',\n","                                              target_size = (img_width,img_height))\n","\n","#class_mode = 'categorical' : 정답은 원핫 인코딩으로 정의됨."]},{"cell_type":"code","execution_count":null,"id":"6554eb97","metadata":{"id":"6554eb97","outputId":"b8563da8-232d-466e-ac95-ff235a384ca4"},"outputs":[{"name":"stdout","output_type":"stream","text":["dict_items([('cats', 0), ('dogs', 1)])\n","dict_items([('cats', 0), ('dogs', 1)])\n"]}],"source":["#정답 확인\n","\n","print(train_data.class_indices.items())\n","print(test_data.class_indices.items())\n","#class_indices : 문자열로 표시되는 데이터 정답이 어떤 숫자로 매칭되는지 확인할 수 있음."]},{"cell_type":"code","execution_count":null,"id":"96b5fb09","metadata":{"id":"96b5fb09"},"outputs":[],"source":["#모델 컴파일 및 학습\n","\n","from datetime import datetime\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","\n","md.compile(loss = 'categorical_crossentropy', optimizer = tf.keras.optimizers.Adam(2e-5),\\\n","          metrics = ['accuracy'])\n","#fine-tuning : 학습률을 낮게 설정해 pre-trained 가중치를 조금씩 업데이트 해주는 것이 핵심,\n","\n","save_file_name = './cats_and_dogs_Xception'\n","\n","checkpoint = ModelCheckpoint(save_file_name, monitor = 'val_loss',\\\n","                            verbose = 1, save_best_only = True, mode = 'auto')\n","\n","es = EarlyStopping(monitor = 'val_loss', patience = 5)\n","\n","hist = md.fit(train_data, epochs = 30, validation_data = test_data, callbacks = [checkpoint, es])"]},{"cell_type":"markdown","id":"2bb4417d","metadata":{"id":"2bb4417d"},"source":[]},{"cell_type":"markdown","id":"fa53b827","metadata":{"id":"fa53b827"},"source":["---------------------------------------------------------------------------------------------------"]},{"cell_type":"markdown","id":"5cb15f61","metadata":{"id":"5cb15f61"},"source":[]},{"cell_type":"markdown","id":"62bf8185","metadata":{"id":"62bf8185"},"source":["## Callback Function -"]},{"cell_type":"markdown","id":"2373d0ff","metadata":{"id":"2373d0ff"},"source":["특정 상황에서 실행되는 함수를 시스템에 등록 -> 해당 상황이 발생됐을 때, 등록된 함수가 실행."]},{"cell_type":"markdown","id":"540ea97a","metadata":{"id":"540ea97a"},"source":[]},{"cell_type":"markdown","id":"7322a2c6","metadata":{"id":"7322a2c6"},"source":["## ReduceLROnPlateau - "]},{"cell_type":"markdown","source":["학습 중 learning rate 변화시킬 수 있는 함수."],"metadata":{"id":"Fp0Ezp9KTx_B"},"id":"Fp0Ezp9KTx_B"},{"cell_type":"code","execution_count":null,"id":"5075d17b","metadata":{"id":"5075d17b"},"outputs":[],"source":["#example)\n","\n","from tensorflow.keras.callbacks import ReduceLROnPlateau\n","\n","reduceLR = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5,\n","                            #val_loss 기준으로 callback 출력 #callback 호출시, 학습률을 1/2 줄임\n","                            patience = 5, verbose = 1)\n","                            #epoch 5 동안 개선되지 않으면 callback 호출, 로그 출력\n","\n","hist = md.fit(xtr, ytr, epochs = 50, validation_split = 0.2, callbacks = [reduceLR])"]},{"cell_type":"markdown","id":"ec423faf","metadata":{"id":"ec423faf"},"source":[]},{"cell_type":"markdown","id":"fd3a91b5","metadata":{"id":"fd3a91b5"},"source":["## ModelCheckpoint -"]},{"cell_type":"markdown","source":["모델 가중치를 중간에 저장할 수 있는 함수."],"metadata":{"id":"jY56lRj3T6tu"},"id":"jY56lRj3T6tu"},{"cell_type":"code","execution_count":null,"id":"f6656f9e","metadata":{"id":"f6656f9e"},"outputs":[],"source":["#example)\n","\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","checkpoint = Modelcheckpoint(file_path, monitor = 'val_loss', verbose = 1,\n","                            #val_loss 값이 개선됐을 때 호출, 로그 출력\n","                            save_best_only = True, mode = 'auto')\n","                            #best 값만 저장, 자동으로 best 값을 찾음.\n","                          \n","\n","hist = md.fit(xtr, ytr, epochs = 50, validation_split = 0.2, callbacks = [checkpoint])"]},{"cell_type":"markdown","id":"0f5267e0","metadata":{"id":"0f5267e0"},"source":[]},{"cell_type":"markdown","id":"89a89724","metadata":{"id":"89a89724"},"source":["## EarlyStopping -"]},{"cell_type":"markdown","source":["모델 성능지표가 일정 시간 개선되지 않을 때 조기 종료시킬 수 있는 함수."],"metadata":{"id":"sDKnLLbsT-7_"},"id":"sDKnLLbsT-7_"},{"cell_type":"code","execution_count":null,"id":"55b538e0","metadata":{"id":"55b538e0"},"outputs":[],"source":["#example)\n","\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","checkpoint = Modelcheckpoint(file_path, monitor = 'val_loss', verbose = 1,\n","                            #val_loss 값이 개선됐을 때 호출, 로그 출력\n","                            save_best_only = True, mode = 'auto')\n","                            #best 값만 저장, 자동으로 best 값을 찾음.\n","    \n","es = EarlyStopping(monitor = 'val_loss', patience = 5)\n","                  #관찰 대상은 val_loss, epochs = 5 동안 개선되지 않으면 학습 종료\n","                          \n","\n","hist = md.fit(xtr, ytr, epochs = 50, validation_split = 0.2, callbacks = [checkpoint, es])"]},{"cell_type":"markdown","id":"42ca9aec","metadata":{"id":"42ca9aec"},"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}